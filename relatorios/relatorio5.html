<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <title>Relatório Lab 5 - Detecção e Correspondência de Características</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 40px;
            background-color: #f5f5f5;
            color: #333;
        }
        header, section {
            background-color: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #1a73e8;
        }
        pre {
            background: #eee;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        img, video {
            max-width: 100%;
            height: auto;
            margin-top: 10px;
            border-radius: 8px;
            display: block;
        }
        footer {
            margin-top: 60px;
            font-size: 0.9em;
            color: #777;
            text-align: center;
        }
        .code-block {
            margin-top: 15px;
        }
        .code-block h3 {
            margin-bottom: 5px;
        }
    </style>
</head>
<body>

    <header>
        <h1>Relatório - Laboratório 5: Detecção e Correspondência de Características</h1>
        <p><strong>Grupo:</strong> 6</p>
        <p><strong>Integrantes:</strong> Guilherme do Amaral, </p>
        <p><strong>Data do experimento:</strong> Julho de 2025</p>
        <p><strong>Data de publicação:</strong> 09 de agosto de 2025</p>
    </header>

    <section>
        <h2>Introdução</h2>
        <p>Este relatório detalha as atividades do Laboratório 5, focado na detecção, descrição e correspondência de características (features) em imagens. O objetivo foi explorar diferentes algoritmos como SIFT, SURF e ORB para encontrar pontos de interesse e realizar o casamento de características entre uma imagem de referência (template) e uma imagem de cena, permitindo a localização de objetos.</p>
    </section>

    <section>
        <h2>Procedimentos e Códigos</h2>
        <p>O experimento foi dividido em etapas, começando com a captura de imagens, a detecção de características e, finalmente, a correspondência para localizar o objeto.</p>

        <div class="code-block">
            <h3>capture_image.py - Captura da Imagem de Cena</h3>
            <p>Primeiro, utilizamos um script para capturar a imagem da cena onde o objeto seria procurado.</p>
            <pre><code>
import cv2

# Inicializa a webcam
cap = cv2.VideoCapture(0) # 0 para a câmera padrão

if not cap.isOpened():
    print("Erro: Não foi possível abrir a câmera.")
else:
    print("Pressione 's' para salvar a imagem e 'q' para sair.")

    while True:
        # Captura frame a frame
        ret, frame = cap.read()
        if not ret:
            print("Erro: Não foi possível ler o frame.")
            break

        # Exibe o frame resultante
        cv2.imshow('Webcam - Pressione "s" para salvar', frame)

        # Espera por uma tecla
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('s'):
            # Salva o frame atual
            cv2.imwrite('imagem_capturada.jpg', frame)
            print("Imagem salva como 'imagem_capturada.jpg'")
            break

    # Libera a câmera e fecha as janelas
    cap.release()
    cv2.destroyAllWindows()
            </code></pre>
        </div>

        <div class="code-block">
            <h3>step1.py - Detecção e Correspondência de Características</h3>
            <p>Este é o script principal que carrega a imagem do objeto e a imagem da cena, utiliza o detector ORB para encontrar pontos de interesse e realiza a correspondência usando BFMatcher para localizar o objeto na cena.</p>
            <pre><code>
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

MIN_MATCH_COUNT = 10

img1 = cv.imread('box.png', cv.IMREAD_GRAYSCALE) # Imagem a ser encontrada
img2 = cv.imread('box_in_scene.png', cv.IMREAD_GRAYSCALE) # Imagem do cenario

# Inicia o detector ORB
orb = cv.ORB_create()

# Encontra os pontos-chave e descritores com o ORB
kp1, des1 = orb.detectAndCompute(img1, None)
kp2, des2 = orb.detectAndCompute(img2, None)

FLANN_INDEX_LSH = 6
index_params= dict(algorithm = FLANN_INDEX_LSH,
                   table_number = 6, # 12
                   key_size = 12,     # 20
                   multi_probe_level = 1) #2
search_params = dict(checks = 50)

flann = cv.FlannBasedMatcher(index_params, search_params)
matches = flann.knnMatch(des1,des2,k=2)

# Armazena todos os bons matches de acordo com o teste de razão de Lowe.
good = []
for m,n in matches:
    if m.distance < 0.7*n.distance:
        good.append(m)

if len(good)>MIN_MATCH_COUNT:
    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)
    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)
    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)
    matchesMask = mask.ravel().tolist()
    h,w = img1.shape
    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)
    dst = cv.perspectiveTransform(pts,M)
    img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)
else:
    print( "Not enough matches are found - {}/{}".format(len(good), MIN_MATCH_COUNT) )
    matchesMask = None

draw_params = dict(matchColor = (0,255,0), # Cor do match em verde
                   singlePointColor = None,
                   matchesMask = matchesMask, # Desenha apenas os inliers
                   flags = 2)
img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)
plt.imshow(img3, 'gray'),plt.show()
            </code></pre>
        </div>
    </section>

    <section>
        <h2>Resultados</h2>
        <h3>Imagem de Resultado</h3>
        <p>A imagem abaixo mostra o resultado final do script. O objeto (a caixa) foi corretamente identificado na cena, e um polígono foi desenhado ao seu redor, indicando o sucesso da correspondência de características.</p>
        <img src="../arquivos/meu_resultado.jpg" alt="Resultado do Feature Matching">

        <h3>Vídeo da Execução</h3>
        <p>O vídeo a seguir demonstra o processo em tempo real, mostrando o sistema localizando o objeto de forma dinâmica.</p>
        <video controls>
            <source src="../arquivos/feature_matching_20250716_222419.mp4" type="video/mp4">
            Seu navegador não suporta vídeos HTML5.
        </video>
    </section>

    <section>
        <h2>Conclusão</h2>
        <p>Este laboratório permitiu uma compreensão prática e aprofundada sobre o funcionamento de algoritmos de detecção e correspondência de características. Observamos que o detector ORB, combinado com o BFMatcher (ou FlannBasedMatcher), é uma solução robusta e eficiente para a localização de objetos em cenários complexos, mesmo com variações de escala, rotação e iluminação. O sucesso na localização do objeto de teste valida a eficácia da abordagem para aplicações de visão computacional.</p>
    </section>

    <footer>
        <p>&copy; 2025 - Grupo 6 - UFABC</p>
    </footer>

</body>
</html>